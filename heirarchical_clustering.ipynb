{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niharika/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import itertools\n",
    "from skimage import io\n",
    "from sklearn import preprocessing\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Heirarchical_cluster/new_data/Daten_Ings/Kontext Phys-Ing_Kinematikgraphen_Rec 01.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantName</th>\n",
       "      <th>MediaName</th>\n",
       "      <th>GazeEventDuration</th>\n",
       "      <th>AOI[Rectangle]Hit</th>\n",
       "      <th>AOI[Rectangle 2]Hit</th>\n",
       "      <th>AOI[Rectangle 3]Hit</th>\n",
       "      <th>AOI[Rectangle 4]Hit</th>\n",
       "      <th>AOI[Rectangle 5]Hit</th>\n",
       "      <th>AOI[Rectangle 6]Hit</th>\n",
       "      <th>AOI[Polygon]Hit</th>\n",
       "      <th>...</th>\n",
       "      <th>AOI[Rectangle 2]Hit.1</th>\n",
       "      <th>AOI[Rectangle 3]Hit.1</th>\n",
       "      <th>AOI[Rectangle 4]Hit.1</th>\n",
       "      <th>AOI[Rectangle 5]Hit.1</th>\n",
       "      <th>AOI[Rectangle 6]Hit.1</th>\n",
       "      <th>AOI[Polygon]Hit.1</th>\n",
       "      <th>AOI[Polygon 2]Hit.1</th>\n",
       "      <th>AOI[Polygon 3]Hit</th>\n",
       "      <th>AOI[Polygon 4]Hit.1</th>\n",
       "      <th>AOI[Polygon 5]Hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAJUKI03</td>\n",
       "      <td>Willkommen_Page_1.png</td>\n",
       "      <td>192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAJUKI03</td>\n",
       "      <td>Willkommen_Page_1.png</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAJUKI03</td>\n",
       "      <td>Willkommen_Page_1.png</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAJUKI03</td>\n",
       "      <td>Willkommen_Page_1.png</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAJUKI03</td>\n",
       "      <td>Willkommen_Page_1.png</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ParticipantName              MediaName  GazeEventDuration  \\\n",
       "0        BAJUKI03  Willkommen_Page_1.png                192   \n",
       "1        BAJUKI03  Willkommen_Page_1.png                 67   \n",
       "2        BAJUKI03  Willkommen_Page_1.png                 91   \n",
       "3        BAJUKI03  Willkommen_Page_1.png                 92   \n",
       "4        BAJUKI03  Willkommen_Page_1.png                 75   \n",
       "\n",
       "   AOI[Rectangle]Hit  AOI[Rectangle 2]Hit  AOI[Rectangle 3]Hit  \\\n",
       "0                NaN                  NaN                  NaN   \n",
       "1                NaN                  NaN                  NaN   \n",
       "2                NaN                  NaN                  NaN   \n",
       "3                NaN                  NaN                  NaN   \n",
       "4                NaN                  NaN                  NaN   \n",
       "\n",
       "   AOI[Rectangle 4]Hit  AOI[Rectangle 5]Hit  AOI[Rectangle 6]Hit  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "\n",
       "   AOI[Polygon]Hit  ...  AOI[Rectangle 2]Hit.1  AOI[Rectangle 3]Hit.1  \\\n",
       "0              NaN  ...                    NaN                    NaN   \n",
       "1              NaN  ...                    NaN                    NaN   \n",
       "2              NaN  ...                    NaN                    NaN   \n",
       "3              NaN  ...                    NaN                    NaN   \n",
       "4              NaN  ...                    NaN                    NaN   \n",
       "\n",
       "   AOI[Rectangle 4]Hit.1  AOI[Rectangle 5]Hit.1  AOI[Rectangle 6]Hit.1  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "\n",
       "   AOI[Polygon]Hit.1  AOI[Polygon 2]Hit.1  AOI[Polygon 3]Hit  \\\n",
       "0                NaN                  NaN                NaN   \n",
       "1                NaN                  NaN                NaN   \n",
       "2                NaN                  NaN                NaN   \n",
       "3                NaN                  NaN                NaN   \n",
       "4                NaN                  NaN                NaN   \n",
       "\n",
       "   AOI[Polygon 4]Hit.1  AOI[Polygon 5]Hit  \n",
       "0                  NaN                NaN  \n",
       "1                  NaN                NaN  \n",
       "2                  NaN                NaN  \n",
       "3                  NaN                NaN  \n",
       "4                  NaN                NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ParticipantName', 'MediaName', 'GazeEventDuration',\n",
       "       'AOI[Rectangle]Hit', 'AOI[Rectangle 2]Hit', 'AOI[Rectangle 3]Hit',\n",
       "       'AOI[Rectangle 4]Hit', 'AOI[Rectangle 5]Hit', 'AOI[Rectangle 6]Hit',\n",
       "       'AOI[Polygon]Hit', 'AOI[Polygon 2]Hit', 'AOI[Polygon 4]Hit',\n",
       "       'AOI[Rectangle 7]Hit', 'AOI[Rectangle]Hit.1', 'AOI[Rectangle 2]Hit.1',\n",
       "       'AOI[Rectangle 3]Hit.1', 'AOI[Rectangle 4]Hit.1',\n",
       "       'AOI[Rectangle 5]Hit.1', 'AOI[Rectangle 6]Hit.1', 'AOI[Polygon]Hit.1',\n",
       "       'AOI[Polygon 2]Hit.1', 'AOI[Polygon 3]Hit', 'AOI[Polygon 4]Hit.1',\n",
       "       'AOI[Polygon 5]Hit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FETCH ALL DATA FROM CSV FILES AND GET AOI SEQUENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class GetData():\n",
    "    def __init__(self,filename):\n",
    "        self.file = filename\n",
    "        self.participant_names = []\n",
    "        self.names = []\n",
    "        self.seq = []\n",
    "        self.frequency = {}\n",
    "        self.gaze = {}\n",
    "        self.final_sequence = []\n",
    "    \n",
    "    def get_names(self,file): #fetch names of all participants\n",
    "        data = pd.read_excel(file)\n",
    "        self.participant_names = data['ParticipantName'][0]\n",
    "        return self.participant_names\n",
    "    \n",
    "    def get_files(self,filename): #fetch all csv files\n",
    "        for f in filename:\n",
    "            self.names.append(self.get_names(f))\n",
    "\n",
    "    #read all csv files from the folder\n",
    "    def get_file(self,file):\n",
    "        page1 = ['PSQN_Page_1.png']\n",
    "        page2 = ['PSQL_Page_1.png']\n",
    "        data = pd.read_excel(file)\n",
    "\n",
    "        data = data[['MediaName','GazeEventDuration','AOI[Rectangle]Hit', 'AOI[Rectangle 2]Hit', 'AOI[Rectangle 3]Hit',\n",
    "           'AOI[Rectangle 4]Hit', 'AOI[Rectangle 5]Hit', 'AOI[Rectangle 6]Hit',\n",
    "           'AOI[Polygon]Hit', 'AOI[Polygon 2]Hit', 'AOI[Polygon 4]Hit',\n",
    "           'AOI[Rectangle 7]Hit', 'AOI[Rectangle]Hit.1', 'AOI[Rectangle 2]Hit.1',\n",
    "           'AOI[Rectangle 3]Hit.1', 'AOI[Rectangle 4]Hit.1',\n",
    "           'AOI[Rectangle 5]Hit.1', 'AOI[Rectangle 6]Hit.1', 'AOI[Polygon]Hit.1',\n",
    "           'AOI[Polygon 2]Hit.1', 'AOI[Polygon 3]Hit', 'AOI[Polygon 4]Hit.1',\n",
    "           'AOI[Polygon 5]Hit']]\n",
    "        data_psqn = data[data.MediaName.isin(page1)]\n",
    "\n",
    "        data_psql = data[data.MediaName.isin(page2)]\n",
    "        data_psqn.columns = ['MediaName','GazeEventDuration','A', 'B','C','D','E','F','G','H','I',\n",
    "                        'J','K','L','M',\n",
    "                        'N','O','P','Q','R','S','T','U']\n",
    "        data_psql.columns = ['MediaName','GazeEventDuration','A', 'B','C','D','E','F','G','H','I',\n",
    "                        'J','K','L','M',\n",
    "                        'N','O','P','Q','R','S','T','U']\n",
    "        return data_psqn,data_psql\n",
    "    \n",
    "    #remove redundancies from scanpath\n",
    "    def cleaned_path(self,x):\n",
    "        length= len(x)\n",
    "        i=0\n",
    "        while(i<length):\n",
    "            #print(i,x[i])\n",
    "            area = x[i][0]\n",
    "            duration = x[i][1]\n",
    "            c = i+1\n",
    "            total_duration = duration\n",
    "            flag = False\n",
    "            try:\n",
    "                while(x[c][0]==area):\n",
    "                    flag = True\n",
    "                    total_duration = total_duration + x[c][1]\n",
    "                    i=c+1\n",
    "                    c= c+1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            self.final_sequence.append((area,total_duration))\n",
    "            if flag == False:\n",
    "                i=i+1\n",
    "        return self.final_sequence\n",
    "    \n",
    "    #get the duration of each AOI in a scanpath sequence\n",
    "    def get_gazedurtion(self,seq):\n",
    "        for s in seq:\n",
    "            #print(s)\n",
    "            if s[0] in self.gaze.keys():\n",
    "                self.gaze[str(s[0])]+=s[1]\n",
    "            else:\n",
    "                self.gaze[str(s[0])]=s[1]\n",
    "        return self.gaze\n",
    "    \n",
    "    #get the number of times an AOI has occured in a scanpath sequence for each participant\n",
    "    def get_frequence(self,seq):\n",
    "        for s in seq:\n",
    "            if s[0] in self.frequency.keys():\n",
    "                self.frequency[str(s[0])]+=1\n",
    "            else:\n",
    "                self.frequency[str(s[0])]=1\n",
    "        return self.frequency\n",
    "    \n",
    "    #function to generate scanpath sequence of each participant from the csv file\n",
    "    def get_sequence(self,data):\n",
    "        #seq = []\n",
    "        GazeEventDuration = []\n",
    "        for index, row in data.iterrows():\n",
    "            if row['A'] == 1:\n",
    "                self.seq.append(('A',row['GazeEventDuration']))\n",
    "            elif row['B'] == 1:\n",
    "                self.seq.append(('B',row['GazeEventDuration']))\n",
    "            elif row['C'] == 1:\n",
    "                self.seq.append(('C',row['GazeEventDuration']))\n",
    "            elif row['D'] == 1:\n",
    "                self.seq.append(('D',row['GazeEventDuration']))\n",
    "            elif row['E'] == 1:\n",
    "                self.seq.append(('E',row['GazeEventDuration']))\n",
    "            elif row['F'] == 1:\n",
    "                self.seq.append(('F',row['GazeEventDuration']))\n",
    "            elif row['G'] == 1:\n",
    "                self.seq.append(('G',row['GazeEventDuration']))\n",
    "            elif row['H'] == 1:\n",
    "                self.seq.append(('H',row['GazeEventDuration']))\n",
    "            elif row['I'] == 1:\n",
    "                self.seq.append(('I',row['GazeEventDuration']))\n",
    "            elif row['J'] == 1:\n",
    "                self.seq.append(('J',row['GazeEventDuration']))\n",
    "            elif row['K'] == 1:\n",
    "                self.seq.append(('K',row['GazeEventDuration']))\n",
    "            elif row['L'] == 1:\n",
    "                self.seq.append(('L',row['GazeEventDuration']))\n",
    "            elif row['M'] == 1:\n",
    "                self.seq.append(('M',row['GazeEventDuration']))\n",
    "            elif row['N'] == 1:\n",
    "                self.seq.append(('N',row['GazeEventDuration']))\n",
    "                #GazeEventDuration.append(row['GazeEventDuration'])\n",
    "            elif row['O'] == 1:\n",
    "                self.seq.append(('O',row['GazeEventDuration']))\n",
    "                #GazeEventDuration.append(row['GazeEventDuration'])\n",
    "            elif row['P'] == 1:\n",
    "                self.seq.append(('P',row['GazeEventDuration']))\n",
    "                #GazeEventDuration.append(row['GazeEventDuration'])\n",
    "            elif row['Q'] == 1:\n",
    "                self.seq.append(('Q',row['GazeEventDuration']))\n",
    "                #GazeEventDuration.append(row['GazeEventDuration'])\n",
    "            elif row['R'] == 1:\n",
    "                self.seq.append(('R',row['GazeEventDuration']))\n",
    "                #GazeEventDuration.append(row['GazeEventDuration'])\n",
    "            elif row['S'] == 1:\n",
    "                self.seq.append(('S',row['GazeEventDuration']))\n",
    "                #GazeEventDuration.append(row['GazeEventDuration'])\n",
    "            elif row['T'] == 1:\n",
    "                self.seq.append(('T',row['GazeEventDuration']))\n",
    "                #GazeEventDuration.append(row['GazeEventDuration'])\n",
    "            elif row['U'] == 1:\n",
    "                self.seq.append(('U',row['GazeEventDuration']))\n",
    "                #GazeEventDuration.append(row['GazeEventDuration'])\n",
    "  \n",
    "        return self.seq\n",
    "\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    paths1 = []\n",
    "    paths2 = []\n",
    "    frequence1 = []\n",
    "    frequence2 = []\n",
    "    t_gaze1 = []\n",
    "    t_gaze2 = []\n",
    "    total_gaze1 =[]\n",
    "    total_gaze2 =[]\n",
    "    names = []\n",
    "    getdata = GetData(filename)\n",
    "    for f in filename:\n",
    "        #names.append(getdata.get_names(f))\n",
    "        data_psqn,data_psql = getdata.get_file(f)\n",
    "        #print(data1.head())\n",
    "        #break\n",
    "        seq1 = getdata.get_sequence(data_psqn)\n",
    "        seq2 = getdata.get_sequence(data_psql)\n",
    "        #print(seq1)\n",
    "        #break\n",
    "\n",
    "        freq1 = getdata.get_frequence(seq1)\n",
    "        freq2 = getdata.get_frequence(seq2)\n",
    "        #print(freq1)\n",
    "        \n",
    "\n",
    "        path1 = getdata.cleaned_path(seq1)\n",
    "        path2 = getdata.cleaned_path(seq2)\n",
    "        \n",
    "\n",
    "        gaze1 = getdata.get_gazedurtion(seq1)\n",
    "        gaze2 = getdata.get_gazedurtion(seq2)\n",
    "        \n",
    "\n",
    "        t_gaze1.append(gaze1)\n",
    "        t_gaze2.append(gaze2)\n",
    "        #print('gaze1 is ',gaze1)\n",
    "\n",
    "        total_gaze1.append(sum(gaze1.values()))\n",
    "        total_gaze2.append(sum(gaze2.values()))\n",
    "\n",
    "\n",
    "        paths1.append(path1)\n",
    "        paths2.append(path2)\n",
    "\n",
    "        frequence1.append(freq1)\n",
    "        frequence2.append(freq2)\n",
    "\n",
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string1 = []\n",
    "# string2 = []\n",
    "# for i in range(len(paths1)):\n",
    "#     #print(paths[i])\n",
    "#     l= [x for (x, y) in paths1[i]]\n",
    "    \n",
    "#     s = ''.join(l)\n",
    "    \n",
    "#     string1.append(s)\n",
    "    \n",
    "# for i in range(len(paths2)):\n",
    "#     #print(paths[i])\n",
    "#     l= [x for (x, y) in paths2[i]]\n",
    "    \n",
    "#     s = ''.join(l)\n",
    "    \n",
    "#     string2.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTION TO CREATE DOTPLOT FOR ALL PARTICIPANT PAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dotplot using the index and scanpath sequences\n",
    "\n",
    "def create_dotplot(indexs):\n",
    "    fcluster = []\n",
    "    index_ = []\n",
    "    psql0_dfs = {}\n",
    "    all = {}\n",
    "    memory = []\n",
    "    participant_length=[]\n",
    "    y_axis = 0\n",
    "    x_axis = 0\n",
    "    x_data = []\n",
    "    for i in range(0,len(indexs),1):\n",
    "        y_data = []\n",
    "        y_data.append(y_axis)\n",
    "        y_axis += len(paths1[indexs[i]])\n",
    "        y_data.append(y_axis)\n",
    "        x_axis = 0\n",
    "        for j in range(0,len(indexs),1):\n",
    "            x_data = []\n",
    "            x_data.append(x_axis)\n",
    "            x_axis += len(paths1[indexs[j]])\n",
    "            x_data.append(x_axis)\n",
    "            print()\n",
    "            id_ = str(i)+'_'+str(j)\n",
    "            id_reverse = str(j)+'_'+str(i)\n",
    "            #print(id_)\n",
    "\n",
    "            arr = np.zeros((len(paths1[indexs[j]]),len(paths1[indexs[i]])),dtype=int)\n",
    "            print(arr.shape)\n",
    "            df2 = pd.DataFrame(arr,columns=[a for (a,g) in paths1[indexs[i]]])\n",
    "            df2.index = [a for (a,g) in paths1[indexs[j]]]\n",
    "            all[id_] = df2.shape\n",
    "            #print(all)\n",
    "            if not i==j and id_ not in memory and id_reverse not in memory:\n",
    "                print('creating dotplot')\n",
    "                participant_length.append((y_data,x_data))\n",
    "                memory.append(id_)\n",
    "                memory.append(id_reverse)\n",
    "                r=0\n",
    "                #try:\n",
    "                for index, row in df2.iterrows():\n",
    "                    c = 0\n",
    "                    #print(r,c)\n",
    "                    while(c<len(paths1[indexs[i]])-1):\n",
    "                        #print(paths2[psql0_index[i]][c][0],paths2[psql0_index[j]][r][0])\n",
    "                        if paths1[indexs[i]][c][0] == paths1[indexs[j]][r][0]:\n",
    "                            aoi = paths1[indexs[i]][c][0]\n",
    "                            df2.iloc[[r], [c]] = (t_gaze1[indexs[j]][aoi] * t_gaze1[indexs[i]][aoi])/(total_gaze1[indexs[i]]*total_gaze1[indexs[j]])\n",
    "\n",
    "                        c = c+1\n",
    "                    r = r+1\n",
    "            \n",
    "\n",
    "            if i==j==0:\n",
    "                psql0_dfs[i] = df2.T\n",
    "            elif j==0 and i>0: #column should match\n",
    "                if psql0_dfs[i-1].shape[1] == df2.shape[1]:\n",
    "                    psql0_dfs[i] = df2\n",
    "                else:\n",
    "                    psql0_dfs[i] = df2.T\n",
    "\n",
    "            else:# row match with base and column with previous\n",
    "                if df2.shape[0] == psql0_dfs[i].shape[0]:\n",
    "                    #print(psql1_dfs[i].shape,df2.shape)\n",
    "                    psql0_dfs[i] = pd.concat([psql0_dfs[i], df2.T], axis=1)\n",
    "                else:\n",
    "                    psql0_dfs[i] = pd.concat([psql0_dfs[i], df2.T], axis=1)\n",
    "              \n",
    "            del df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUB-MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Functions_():\n",
    "    def __init__(self):\n",
    "        self.f=[]\n",
    "    \n",
    "    def subdata(self,df_norm,region):\n",
    "        X =[]\n",
    "        y = []\n",
    "        for i in range(len(df_norm.index)):\n",
    "            for j in range(len(df_norm.columns)):\n",
    "                #print(i,j)\n",
    "                #cell_data = {}\n",
    "                #weight = []\n",
    "                #coordinates = []\n",
    "                if df_norm.iloc[i,j] > 0 and i>region[0] and i<region[1] and j>region[2] and j<region[3]:\n",
    "                    X.append(j)\n",
    "                    y.append(i)\n",
    "        return X,y\n",
    "\n",
    "\n",
    "    def points_(self,coef,intercept,df_norm):\n",
    "        points = []\n",
    "        for i in range(len(df_norm.index)):\n",
    "            for j in range(len(df_norm.columns)):\n",
    "                #print(i,j)\n",
    "                try:\n",
    "                    if df_norm.iloc[i,j] > 0:\n",
    "                        y = int(j*coef + intercept)\n",
    "                        #print(y,i,(i,j))\n",
    "                        if y == i or abs(y-i)<1:\n",
    "                            #print('found ',y,i)\n",
    "                            points.append((i,j))\n",
    "                except:\n",
    "                    print('out of bounds')\n",
    "\n",
    "        return points\n",
    "\n",
    "    def getlengths(self,cluster):\n",
    "        #length = []\n",
    "        length = [len(x) for x in cluster]\n",
    "        length = list(set(length))\n",
    "        return length  \n",
    "\n",
    "    #perform regression on dotplots\n",
    "    def regression(self,df_norm):\n",
    "        cluster = []\n",
    "        lines = []\n",
    "        for l in participant_length:\n",
    "            y0 = l[0][0]\n",
    "            y1 = l[0][1]\n",
    "            x0 = l[1][0]\n",
    "            x1 = l[1][1]\n",
    "            distance = 0.66*(y1-y0)\n",
    "            #print(distance)\n",
    "            for i in range(x0,x1,10):\n",
    "                for j in range(y0,y1,10):\n",
    "                    X,y= self.subdata(df_norm,[j,j+distance,i,i+distance])\n",
    "                    X = np.array(X)\n",
    "                    y = np.array(y)\n",
    "                    #print(X.shape,X,y.shape,y)\n",
    "                    try:\n",
    "                        reg = LinearRegression().fit(X.reshape(-1,1), y)\n",
    "                        points = self.points_(reg.coef_,reg.intercept_,df_norm)\n",
    "                        lines.append((reg.coef_,reg.intercept_))\n",
    "                        cluster.append(points)\n",
    "                        print(points)\n",
    "                    except:\n",
    "                        print('dskncskdj')\n",
    "        return cluster,lines\n",
    "\n",
    "    def longestSubstringFinder(self,string1,weight1,a, string2,weight2,b):\n",
    "        answer = \"\"\n",
    "        len1, len2 = len(string1), len(string2)\n",
    "        coordinates = []\n",
    "        for i in range(len1):\n",
    "            match = \"\"\n",
    "            val = 0\n",
    "\n",
    "            for j in range(len2):\n",
    "                if (i + j < len1 and string1[i + j] == string2[j]):\n",
    "                    match += string2[j]\n",
    "                    val += weight1[i]+weight2[j]\n",
    "                    coordinates.append(a[i])\n",
    "                    coordinates.append(b[j])\n",
    "                    #print(val)\n",
    "                else:\n",
    "                    if (len(match) > len(answer)): answer = match\n",
    "                    match = \"\"\n",
    "                    #val = 0\n",
    "        return answer,val,list(set(coordinates))\n",
    "\n",
    "    def get_string(self,stri):\n",
    "        string = []\n",
    "        weight = []\n",
    "        for (m,n) in stri:\n",
    "            string.append(base.columns[n]) #use df_norm name\n",
    "            weight.append(base.iloc[m][n])\n",
    "        return ''.join(string),weight\n",
    "\n",
    "\n",
    "    def compute_dist(self,a,b):\n",
    "        match,weight = get_string(a)\n",
    "        match_,weight_ = get_string(b)\n",
    "        matchstring,val,coordinates = longestSubstringFinder(match,weight,a,match_,weight_,b)\n",
    "        return [len(matchstring),val,matchstring,coordinates]\n",
    "\n",
    "\n",
    "    #compute distances\n",
    "    def compute_dist_dict(self,fcluster__):\n",
    "        distance = {}\n",
    "        for i in range(0,len(fcluster__),1):\n",
    "            each_dist = {}\n",
    "            for j in range(0,len(fcluster__),1):\n",
    "                #print(i,j)\n",
    "                if i==j:\n",
    "                    dist = [0,0,'']\n",
    "                    #continue\n",
    "                else:\n",
    "                    dist = compute_dist(fcluster__[i],fcluster__[j])\n",
    "                each_dist[j] = dist\n",
    "            #print(each_dist)\n",
    "            distance[i] = each_dist\n",
    "        return distance\n",
    "\n",
    "    #remove redundancy\n",
    "    def remove_redundancy(self,fcluster_):\n",
    "        fcluster__=[]\n",
    "        for f in fcluster_:\n",
    "            x = []\n",
    "            #get unique x coordinates\n",
    "            x_coord = [x for (x,y) in f]\n",
    "            #print(set(x_coord))\n",
    "            for xc in x_coord:\n",
    "                #print(xc)\n",
    "                unique_x = [i for i in f if i[0]==xc]\n",
    "                #print(unique_x)\n",
    "                if len(unique_x)>1:\n",
    "                    for j in unique_x:\n",
    "                        #all_x = [item for item in f if item[0] == unique_x]\n",
    "                        val = [df_norm.iloc[v[0]][v[1]] for v in unique_x]\n",
    "                        max_index = val.index(max(val))\n",
    "                        x.append(unique_x[max_index])\n",
    "                        #print(val,))\n",
    "                        #print(j,df_norm.iloc[j[0]][j[1]])\n",
    "\n",
    "                        #print([df_norm.iloc[v[0]][v[1]] for v in all_x])\n",
    "                else:\n",
    "                    x.append(unique_x[0])\n",
    "            fcluster__.append(list(set(x)))  \n",
    "        return fcluster__\n",
    "    \n",
    "\n",
    "\n",
    "    def H_cluster(self,fcluster__): #heirarchical clustering\n",
    "        common_seq = []\n",
    "        while(len(fcluster__) >0):\n",
    "            print(len(fcluster__))\n",
    "            distance = self.compute_dist_dict(fcluster__) \n",
    "            #print(distance)\n",
    "            bestmatch = {}\n",
    "            for i in range(len(distance.keys())):\n",
    "                new_data = {k: v for k, v in distance[i].items() if not v[1] == 0}\n",
    "                #print('new_data',new_data)\n",
    "                if len(new_data)>0:\n",
    "                    bestmatch[i] = max(new_data.items(), key = lambda k : k[1])\n",
    "            print('best match is ',max(bestmatch.items(), key = lambda k : k[1]))\n",
    "            mergeitems = max(bestmatch.items(), key = lambda k : k[1])\n",
    "            common_seq.append([mergeitems[0],mergeitems[1][0],mergeitems[1][1][2]])\n",
    "            print(common_seq)\n",
    "            #fcluster_.pop(mergeitems[0])\n",
    "            #fcluster_.pop(mergeitems[1][0])\n",
    "            remove_indices = [mergeitems[0],mergeitems[1][0]]\n",
    "            fcluster__ = [i for j, i in enumerate(fcluster__) if j not in remove_indices]\n",
    "            fcluster__.append(mergeitems[1][1][3])\n",
    "            #print(fcluster_)\n",
    "        return common_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths1 = []\n",
    "paths2 = []\n",
    "frequence1 = []\n",
    "frequence2 = []\n",
    "t_gaze1 = []\n",
    "t_gaze2 = []\n",
    "total_gaze1 =[]\n",
    "total_gaze2 =[]\n",
    "names = []\n",
    "psql0_index = [] # particiapnts who scored 0 in psql\n",
    "psqn0_index = [] # particiapnts who scored 0 in psqn\n",
    "psql1_index = [] # particiapnts who scored 1 in psql\n",
    "psqn1_index = [] # particiapnts who scored 1 in psqn\n",
    "num = 3  \n",
    "threshold = 0\n",
    "len_threshold = 6\n",
    "\n",
    "#fetch names of all participants\n",
    "def get_names(file):\n",
    "    data = pd.read_excel(file)\n",
    "    name = data['ParticipantName'][0]\n",
    "    return name\n",
    "\n",
    "\n",
    "    \n",
    "def get_scores(names):\n",
    "    #get index of all participants on the basis of scores and store them in above list\n",
    "    for n in names:\n",
    "        index = grade.loc[grade['Participant'] == n, 'PSQL'].index.item()\n",
    "        psql = grade.loc[grade['Participant'] == n, 'PSQL'].iloc[0]\n",
    "        psqn = grade.loc[grade['Participant'] == n, 'PSQN'].iloc[0]\n",
    "        if psql == 0:\n",
    "            psql0_index.append(index)\n",
    "        else:\n",
    "            psql1_index.append(index)\n",
    "        if psqn == 0:\n",
    "            psqn0_index.append(index)\n",
    "        else:\n",
    "            psqn1_index.append(index)\n",
    "    \n",
    "def main_(num,threshold,len_threshold):\n",
    "    filename = glob.glob(\"/home/niharika/notebooks/Heirarchical_cluster/new_data/Daten_Ings/*\")\n",
    "    for f in filename:\n",
    "        names.append(get_names(f))\n",
    "    print(names)\n",
    "    grade = pd.read_excel('Heirarchical_cluster/new_data/Korrektheit_PSQL_PSQN.xlsx',sheet_name='Tabelle2')\n",
    "    grade.index=grade['Participant']\n",
    "    grade = grade.reindex(names)\n",
    "    grade.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "\n",
    "    getdata = GetData(filename)\n",
    "    for f in filename:\n",
    "        print(f)\n",
    "        #names.append(getdata.get_names(f))\n",
    "        data_psqn,data_psql = getdata.get_file(f)\n",
    "        #print(data1.head())\n",
    "        #break\n",
    "        seq1 = getdata.get_sequence(data_psqn)\n",
    "        seq2 = getdata.get_sequence(data_psql)\n",
    "        #print(seq1)\n",
    "        #break\n",
    "\n",
    "        freq1 = getdata.get_frequence(seq1)\n",
    "        freq2 = getdata.get_frequence(seq2)\n",
    "        #print(freq1)\n",
    "        \n",
    "\n",
    "        path1 = getdata.cleaned_path(seq1)\n",
    "        path2 = getdata.cleaned_path(seq2)\n",
    "        \n",
    "\n",
    "        gaze1 = getdata.get_gazedurtion(seq1)\n",
    "        gaze2 = getdata.get_gazedurtion(seq2)\n",
    "        \n",
    "\n",
    "        t_gaze1.append(gaze1)\n",
    "        t_gaze2.append(gaze2)\n",
    "        #print('gaze1 is ',gaze1)\n",
    "\n",
    "        total_gaze1.append(sum(gaze1.values()))\n",
    "        total_gaze2.append(sum(gaze2.values()))\n",
    "\n",
    "\n",
    "        paths1.append(path1)\n",
    "        paths2.append(path2)\n",
    "\n",
    "        frequence1.append(freq1)\n",
    "        frequence2.append(freq2)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    get_scores(names)\n",
    "    indexs = list(set(psql0_index))\n",
    "    indexs = indexs[:num]\n",
    "    print('indexs ',indexs)\n",
    "    create_dotplot(indexs)\n",
    "    \n",
    "    #concatenate all dotplots\n",
    "    for i in range(0,len(indexs),1):\n",
    "        if i==0:\n",
    "            base = psql0_dfs[i]\n",
    "        else:\n",
    "            base = pd.concat([base,psql0_dfs[i]], axis=0)\n",
    "            \n",
    "    x = base.values #returns a numpy array\n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x)\n",
    "    df_norm = df.apply(lambda x: np.where(x==threshold,0,x)) #replace values in dotplot\n",
    "    cluster,lines = regression(df_norm)\n",
    "    clusterf =[]\n",
    "    for c in cluster:\n",
    "        #print(c)\n",
    "        if not len(c)==0:\n",
    "            if not len(set([c1[0] for c1 in c])) == 1:\n",
    "                #print('found ',c)\n",
    "                clusterf.append(c)\n",
    "    fcluster = []\n",
    "    cluster_refined = list(k for k,_ in itertools.groupby(clusterf))\n",
    "    c = []\n",
    "    for line in cluster_refined:\n",
    "        if len(line)>5:\n",
    "            c.append(line)\n",
    "    fcluster.append(c)\n",
    "    modules_ = Functions()\n",
    "    fcluster_ = fcluster[0]\n",
    "    fcluster__ = modules_.remove_redundancy(fcluster_)\n",
    "    fcluster__ = [v for v in fcluster__ if len(v)>len_threshold]\n",
    "    common_seq = modules_.H_cluster(fcluster__)\n",
    "    print(common_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_(3,0,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
